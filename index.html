<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Prajwal Ganugula | Computer Vision, LLMs, and AI Systems</title>
    <meta
      name="description"
      content="Portfolio of Prajwal Ganugula — ASU graduate student focused on computer vision, LLMs, NLP, deep learning, and data systems engineering."
    />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@400;500;600;700&family=JetBrains+Mono:wght@500&family=Libre+Baskerville:wght@400;700&display=swap"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header class="hero" id="top">
      <nav class="nav">
        <a class="nav__logo" href="#top">PG</a>
        <button class="nav__toggle" aria-label="Toggle navigation">
          <span></span>
          <span></span>
          <span></span>
        </button>
        <ul class="nav__links">
          <li><a href="#focus">Focus</a></li>
          <li><a href="#experience">Experience</a></li>
          <li><a href="#projects">Projects</a></li>
          <li><a href="#research">Research</a></li>
          <li><a href="#skills">Skills</a></li>
          <li><a href="#resume">Resume</a></li>
          <li><a href="#contact">Contact</a></li>
        </ul>
      </nav>

      <div class="hero__content">
        <div class="hero__intro">
          <p class="hero__overline">
            Computer Vision · LLMs &amp; NLP · Deep Learning · ETL Systems
          </p>
          <h1>
            Prajwal Ganugula builds vision and language systems that ship with
            research-grade rigor.
          </h1>
          <p class="hero__summary">
            Graduate student at Arizona State University, previously building
            diffusion and LLM systems at OPLUS. I specialize in computer vision,
            multimodal learning, and production data pipelines that keep models
            grounded, fast, and reliable.
          </p>
          <div class="hero__actions">
            <a class="btn" href="#projects">View Selected Work</a>
            <a class="btn btn--ghost" href="#resume">Download Resume</a>
          </div>
          <ul class="hero__meta">
            <li><span>Tempe, Arizona</span></li>
            <li><a href="tel:+14809423759">+1 480 942 3759</a></li>
            <li><a href="mailto:pganugul@asu.edu">pganugul@asu.edu</a></li>
            <li>
              <a href="https://linkedin.com/in/prajwal-ganugula" target="_blank" rel="noreferrer">
                linkedin.com/in/prajwal-ganugula
              </a>
            </li>
          </ul>
        </div>
        <aside class="hero__panel">
          <div class="panel__section">
            <h2>Current Focus</h2>
            <ul>
              <li>Vision-language pipelines for on-device and scalable inference.</li>
              <li>Evaluation-first LLM systems with grounded retrieval.</li>
              <li>ETL automation that keeps data quality and latency in check.</li>
            </ul>
          </div>
          <div class="panel__metrics">
            <div>
              <span class="metric__value">8×</span>
              <span class="metric__label">Diffusion speed-up with distillation</span>
            </div>
            <div>
              <span class="metric__value">70%</span>
              <span class="metric__label">Manual toil cut via IaC &amp; CI/CD</span>
            </div>
            <div>
              <span class="metric__value">2</span>
              <span class="metric__label">Peer-reviewed publications</span>
            </div>
          </div>
        </aside>
      </div>
    </header>

    <main>
      <section id="focus" class="section section--grid">
        <div class="section__heading">
          <h2>Focus Areas</h2>
          <p>Formal, production-minded work across vision, language, and data systems.</p>
        </div>
        <div class="focus-grid">
          <article class="focus-card">
            <h3>Computer Vision &amp; Multimodal</h3>
            <p>
              Diffusion distillation, segmentation, and vision-language systems tuned
              for controllable outputs.
            </p>
            <ul>
              <li>On-device inference optimization for mobile hardware.</li>
              <li>CLIP-guided segmentation and stylization pipelines.</li>
            </ul>
          </article>
          <article class="focus-card">
            <h3>LLMs &amp; NLP</h3>
            <p>
              Retrieval-augmented pipelines with rigorous evaluation and safety checks.
            </p>
            <ul>
              <li>Hybrid retrieval with reranking and structured prompting.</li>
              <li>LLM evaluation for faithfulness, relevance, and completeness.</li>
            </ul>
          </article>
          <article class="focus-card">
            <h3>Deep Learning Systems</h3>
            <p>
              Efficient training, compression, and inference across GPU and edge stacks.
            </p>
            <ul>
              <li>Quantization, pruning, and performance benchmarking.</li>
              <li>TensorRT, ONNX, and memory-aware optimization.</li>
            </ul>
          </article>
          <article class="focus-card">
            <h3>ETL &amp; Data Engineering</h3>
            <p>
              Reliable pipelines for ingestion, observability, and data contract enforcement.
            </p>
            <ul>
              <li>Airflow, Kafka, and schema validation workflows.</li>
              <li>Latency monitoring and automated remediation.</li>
            </ul>
          </article>
        </div>
      </section>

      <section id="experience" class="section">
        <div class="section__heading">
          <h2>Experience</h2>
          <p>Applied research and production engineering in high-impact environments.</p>
        </div>
        <div class="timeline">
          <article class="timeline__item">
            <header>
              <h3>Software Engineer · Deep Learning Research</h3>
              <span>OPLUS (OPPO · OnePlus) · Hyderabad, India</span>
              <time>Jun 2022 – Aug 2024</time>
            </header>
            <ul>
              <li>
                Designed lightweight LLM chatbots for mobile, cutting inference latency
                while adding multilingual understanding for user insights.
              </li>
              <li>
                Distilled Stable Diffusion with step-aware training, shrinking UNet by 50%
                and delivering 8× faster synthesis on-device.
              </li>
              <li>
                Automated training and benchmarking with PyTorch, ONNX, TensorRT, Docker,
                and Bash for repeatable performance wins.
              </li>
            </ul>
          </article>
          <article class="timeline__item">
            <header>
              <h3>Software Engineer · Infrastructure Team</h3>
              <span>ASU Decision Theater Network · Tempe, AZ</span>
              <time>Dec 2024 – Present</time>
            </header>
            <ul>
              <li>
                Engineered orchestration scripts and observability tooling that streamline
                ETL analytics across AWS and on-prem clusters.
              </li>
              <li>
                Built RESTful services with FastAPI and PostgreSQL for internal dashboards,
                improving data access latency by 30%.
              </li>
              <li>
                Reduced manual build effort by 70% through GitHub Actions and Docker-based
                deployments.
              </li>
            </ul>
          </article>
          <article class="timeline__item">
            <header>
              <h3>Machine Learning Engineer · Internship</h3>
              <span>Samsung R&amp;D Institute · Delhi, India</span>
              <time>Jun 2021 – Jul 2021</time>
            </header>
            <ul>
              <li>
                Benchmarked BERT and RoBERTa pipelines for NER and classification with MLflow
                tracking and DVC-powered CI integrations.
              </li>
              <li>
                Shipped a MobileBERT sentiment service on FastAPI with Dockerized deployment
                and automated retraining via Azure DevOps.
              </li>
            </ul>
          </article>
        </div>
      </section>

      <section id="projects" class="section section--grid">
        <div class="section__heading">
          <h2>Selected Projects</h2>
          <p>Representative work across computer vision, LLM systems, and ETL engineering.</p>
        </div>
        <div class="cards">
          <article class="card">
            <header>
              <h3>AI Eraser for Mobile Photos</h3>
              <span>OPLUS · 2023</span>
            </header>
            <p>
              Built an on-device object removal pipeline with Edge-SAM selection and
              diffusion-based inpainting optimized for mobile latency budgets.
            </p>
            <ul>
              <li>
                <a href="https://www.youtube.com/watch?v=O0cHGDrPNTA" target="_blank" rel="noreferrer">
                  Product demo video ↗
                </a>
              </li>
              <li>
                <a
                  href="https://www.oppo.com/en/newsroom/stories/perfect-your-photos-with-ai-eraser/"
                  target="_blank"
                  rel="noreferrer"
                >
                  OPPO blog feature ↗
                </a>
              </li>
            </ul>
          </article>
          <article class="card">
            <header>
              <h3>Structured Image Captioning with Distributed Training</h3>
              <span>Mar 2024 – Present</span>
            </header>
            <p>
              Architected BLIP-2 + ViT-G fused with FLAN-T5 via QLoRA, then aligned with
              DPO-RLHF to deliver schema-aware captions for enterprise pipelines.
            </p>
            <ul>
              <li>Generated templated datasets for controllable captioning.</li>
              <li>Scaled PEFT training with DeepSpeed ZeRO-3 and FSDP.</li>
            </ul>
          </article>
          <article class="card">
            <header>
              <h3>Efficient Retrieval-Augmented Generation Pipeline</h3>
              <span>Nov 2023 – Feb 2024</span>
            </header>
            <p>
              Built a full-stack RAG platform combining FAISS + ColBERT retrieval with a
              quantized BGE reranker to deliver precise answers on tight SLAs.
            </p>
            <ul>
              <li>Deployed ONNX-accelerated reranker through FastAPI and Docker.</li>
              <li>Improved answer precision by 22% while maintaining latency budgets.</li>
            </ul>
          </article>
        </div>
      </section>

      <section id="research" class="section">
        <div class="section__heading">
          <h2>Research &amp; Publications</h2>
          <p>Selected publications and visual artifacts from MOSAIC and related work.</p>
        </div>
        <div class="research">
          <div class="research__summary">
            <h3>MOSAIC: Multi-Object Segmented Arbitrary Stylization Using CLIP</h3>
            <p>
              Proceedings of ICCV Workshops, 2023. Introduced the first text-guided,
              object-wise stylization method leveraging CLIP, segmentation transformers,
              and diffusion for granular artistic control.
            </p>
            <ul>
              <li>
                <a
                  href="https://openaccess.thecvf.com/content/ICCV2023W/NIVT/papers/Ganugula_MOSAIC_Multi-Object_Segmented_Arbitrary_Stylization_Using_CLIP_ICCVW_2023_paper.pdf"
                  target="_blank"
                  rel="noreferrer"
                >
                  Read the paper ↗
                </a>
              </li>
              <li>
                <a href="https://arxiv.org/abs/2309.13716" target="_blank" rel="noreferrer">
                  arXiv preprint ↗
                </a>
              </li>
            </ul>
          </div>
          <div class="research__gallery">
            <figure>
              <img
                src="assets/img/mosaic-page-1.png"
                alt="MOSAIC paper cover showing stylization overview."
                loading="lazy"
              />
              <figcaption>Overview of MOSAIC stylization pipeline.</figcaption>
            </figure>
            <figure>
              <img
                src="assets/img/mosaic-page-3.png"
                alt="Sample stylized images with segmented objects from MOSAIC paper."
                loading="lazy"
              />
              <figcaption>Per-object style control outputs driven by text prompts.</figcaption>
            </figure>
            <figure>
              <img
                src="assets/img/mosaic-page-6.png"
                alt="Quantitative and qualitative comparisons from MOSAIC paper."
                loading="lazy"
              />
              <figcaption>Comparative results vs. diffusion-based baselines.</figcaption>
            </figure>
          </div>
        </div>
        <div class="publications">
          <article>
            <h3>Application for Produced Crop Price Forecasting Through Deep Learning</h3>
            <p>
              IRJMETS, Nov 2023. Built deep learning pipelines to predict crop pricing trends
              and empower data-informed agriculture.
            </p>
          </article>
        </div>
      </section>

      <section id="skills" class="section section--grid">
        <div class="section__heading">
          <h2>Technical Stack</h2>
          <p>Core tools across vision, language, and production data systems.</p>
        </div>
        <div class="skills">
          <div class="skill-group">
            <h3>Languages</h3>
            <ul>
              <li>Python</li>
              <li>C++</li>
              <li>SQL</li>
              <li>Bash</li>
              <li>JavaScript</li>
            </ul>
          </div>
          <div class="skill-group">
            <h3>Vision &amp; Multimodal</h3>
            <ul>
              <li>PyTorch</li>
              <li>TensorFlow</li>
              <li>Diffusers</li>
              <li>Segmentation</li>
              <li>TensorRT</li>
              <li>ONNX</li>
            </ul>
          </div>
          <div class="skill-group">
            <h3>LLMs &amp; NLP</h3>
            <ul>
              <li>Instruction tuning</li>
              <li>QLoRA</li>
              <li>RAG</li>
              <li>LangChain</li>
              <li>LangGraph</li>
              <li>Evaluation</li>
            </ul>
          </div>
          <div class="skill-group">
            <h3>ETL &amp; Systems</h3>
            <ul>
              <li>Airflow</li>
              <li>Kafka</li>
              <li>FastAPI</li>
              <li>Docker</li>
              <li>Kubernetes</li>
              <li>GitHub Actions</li>
            </ul>
          </div>
          <div class="skill-group">
            <h3>Data Systems</h3>
            <ul>
              <li>Apache Spark</li>
              <li>Hadoop</li>
              <li>PostgreSQL</li>
              <li>Redshift</li>
            </ul>
          </div>
          <div class="skill-group">
            <h3>Cloud &amp; Ops</h3>
            <ul>
              <li>AWS</li>
              <li>Azure</li>
              <li>Observability</li>
              <li>CI/CD</li>
            </ul>
          </div>
        </div>
      </section>

      <section id="resume" class="section">
        <div class="section__heading">
          <h2>Resume</h2>
          <p>AI/ML resume focused on computer vision, LLMs, and data systems work.</p>
        </div>
        <div class="resume-card">
          <div>
            <h3>AI/ML Resume</h3>
            <p>
              Focused on LLMs, NLP, computer vision, and applied data systems engineering.
            </p>
          </div>
          <div class="resume-card__actions">
            <a class="btn" href="assets/docs/prajwal-ganugula-ai-ml-resume.pdf">
              Download PDF
            </a>
            <p class="resume-card__hint">
              Add the PDF at <code>assets/docs/prajwal-ganugula-ai-ml-resume.pdf</code>.
            </p>
          </div>
        </div>
      </section>

      <section id="contact" class="section section--grid contact">
        <div class="section__heading">
          <h2>Contact</h2>
          <p>Open to research collaborations and engineering roles across AI systems.</p>
        </div>
        <div class="contact__grid">
          <div class="contact__links">
            <a class="contact__link" href="mailto:pganugul@asu.edu">pganugul@asu.edu</a>
            <a
              class="contact__link"
              href="https://linkedin.com/in/prajwal-ganugula"
              target="_blank"
              rel="noreferrer"
            >
              LinkedIn
            </a>
            <a
              class="contact__link"
              href="https://github.com/prajwalganugula"
              target="_blank"
              rel="noreferrer"
            >
              GitHub
            </a>
          </div>
          <div class="contact__cta">
            <p>
              Prefer a structured intro? Send a brief with team goals and I will respond
              with tailored case studies.
            </p>
            <a class="btn btn--ghost" href="mailto:pganugul@asu.edu?subject=Let%E2%80%99s%20collaborate">
              Start the conversation
            </a>
          </div>
        </div>
      </section>
    </main>

    <footer class="footer">
      <p>© <span id="year"></span> Prajwal Ganugula. Built with clarity and care.</p>
      <a class="footer__top" href="#top">Back to top ↑</a>
    </footer>

    <script src="script.js"></script>
  </body>
</html>
